# # -*- coding:utf-8 -*-
# import scrapy
# from scrapy.http import Request
# from scrapy import Selector
# from ESearch.items import XiangmuItem
# from ESearch.utils.common import get_md5
#
#
# class DmozSpider(scrapy.Spider):
#     name = "chaoxing"
#     start_urls = []
#     main_url = "http://book.chaoxing.com"
#
#     def start_requests(self):
#         file_object = open(r'chaoxing_url.csv', 'r')
#         try:
#             for line in file_object:
#                 x = line.strip()
#                 self.start_urls.append(x)
#                 start = x.split('_')[0] + "_" + x.split('_')[1]
#                 for i in range(200):
#                     self.start_urls.append(start + "__page_" + str(i+2) + ".html?vip=false")
#             for url in self.start_urls:
#                 yield self.make_requests_from_url(url)
#         finally:
#             file_object.close()
#
#     def parse(self, response):
#         item = XiangmuItem()
#
#         item["book_name"] = ''
#         item["book_author"] = ''
#         item["book_type"] = ''
#         item["book_format"] = ''
#         item["book_time"] = ''
#         item["book_url"] = ''
#         item["book_size"] = ''
#         item["book_downl_url"] = ''
#         item["book_source"] = ''
#         item["book_intro"] = ''
#         item["book_content"] = ''
#         item["book_zip_pswd"] = ''
#         item["book_chinese"] = ''
#         item["book_id"] = ''
#
#         selector = Selector(response)
#         is_lists_page = selector.xpath('//ul[@class="list"]')
#         if is_lists_page:
#             info_lists = is_lists_page.xpath('li/div[@class="pic_upost"]/a/@href').extract()
#             for each in info_lists:
#                 yield Request(self.main_url + each, callback=self.parse)
#
#             # next_link = selector.xpath('//a[@v="next"]/@href').extract()
#             # yield Request(self.main_url + next_link[0], callback=self.parse)
#
#         is_info_page = selector.xpath('//div[@class="box_title"]')
#         if is_info_page:
#
#             item["book_name"] = selector.xpath('//div[@class="box_title"]/h1/text()').extract()
#             info = selector.xpath('//ul[@class="text01"]')
#             item["book_type"] = info.xpath('li')[-1].xpath('a/text()').extract()
#             author = info.xpath('li/text()').extract()[0]
#             item["book_author"] = ''.join(author).split('>')[-1]
#             source = info.xpath('li/text()').extract()[2]
#             item["book_source"] = ''.join(source).split('>')[-1]
#             size = info.xpath('li/text()').extract()[3]
#             item["book_size"] = ''.join(size).split('>')[-1] + 'é¡µ'
#
#             intro = selector.xpath('//div[@class="abut_top_part"]/text()').extract()
#             if intro:
#                 item['book_intro'] = intro
#
#             item["book_url"] = response.url
#             item["book_downl_url"] = response.url
#             item["book_id"] = get_md5(response.url)
#             yield item
#
#
#
