# # -*- coding:utf-8 -*-
# import scrapy
# import re
# import urllib2
# from scrapy.http import Request
# from scrapy import Selector
# from ESearch.items import XiangmuItem
# from ESearch.utils.common import get_md5
#
#
# # 32406
# class DmozSpider(scrapy.Spider):
#     name = "haoyang"
#     start_urls = []
#     main_url = "http://www.9lizhi.com"
#
#     def start_requests(self):
#         file_object = open(r'haoyang_url.csv', 'r')
#         try:
#             for line in file_object:
#                 x = line.strip()
#                 self.start_urls.append(x)
#             for url in self.start_urls:
#                 yield self.make_requests_from_url(url)
#         finally:
#             file_object.close()
#
#     def parse(self, response):
#         item = XiangmuItem()
#
#         item["book_name"] = ''
#         item["book_author"] = ''
#         item["book_type"] = ''
#         item["book_format"] = ''
#         item["book_time"] = ''
#         item["book_url"] = ''
#         item["book_size"] = ''
#         item["book_downl_url"] = ''
#         item["book_source"] = ''
#         item["book_intro"] = ''
#         item["book_content"] = ''
#         item["book_zip_pswd"] = ''
#         item["book_chinese"] = ''
#         item["book_id"] = ''
#
#         selector = Selector(response)
#
#         is_lists_page = selector.xpath('//ul[@id="resultsContainer"]')
#         if is_lists_page:
#             info_lists = is_lists_page.xpath('li/div[@class="item_title"]/strong/h2/a/@href').extract()
#             for each in info_lists:
#                 yield Request(each, callback=self.parse)
#
#             page_lists = is_lists_page.xpath('//select[@name="select"]/option/@value').extract()
#             for each_page in page_lists[1:-1]:
#                 yield Request(self.main_url + each_page, callback=self.parse)
#             pass
#
#         is_info_page = selector.xpath('//div[@id="detail"]')
#         if is_info_page:
#             item['book_url'] = response.url
#             item['book_id'] = get_md5(response.url)
#             item['book_downl_url'] = response.url
#
#             type = selector.xpath('//div[@class="posi"]/a/text()').extract()
#             type_url = selector.xpath('//div[@class="posi"]/a/@href').extract()
#             if "http://www" in type_url[-1]:
#                 item['book_type'] = type[-2]
#             else:
#                 item['book_type'] = type[-1]
#
#             information = is_info_page.xpath('div[@class="tb-detail-hd"]')
#             item['book_name'] = information.xpath('h1/text()').extract()
#             time = information.xpath('li[@class="dated"]/span[@class="datetime"]/text()').extract()
#             time = ''.join(time).split('ï¼š')[-1]
#             item['book_time'] = time
#             author = information.xpath('li[@class="dated"]/span[@class="author"]/text()').extract()
#             item['book_author'] = ''.join(author).replace('\r', '').replace('\n', '')
#             yield item
#
#
